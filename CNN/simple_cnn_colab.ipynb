{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dccd2c2",
   "metadata": {},
   "source": [
    "# CNN simples para Google Colab (versão melhorada)\n",
    "\n",
    "Este notebook treina uma pequena rede convolucional (CNN) no conjunto MNIST. Ele foi preparado para rodar diretamente no Google Colab e contém instruções, instalação de dependências, checagem de ambiente, treino com callbacks e salvamento do modelo no Drive.\n",
    "\n",
    "**Checklist antes de começar**:\n",
    "- (Colab) Runtime → Change runtime type → GPU.\n",
    "- Execute as células em ordem.\n",
    "- Célula 1 instala dependências somente quando detectar Colab; em local, siga as instruções na célula correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28916a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1 — Instala dependências (apenas no Colab)\n",
    "# Detecta Colab de forma segura e instala pacotes necessários.\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Google Colab detectado — instalando dependências (tensorflow, matplotlib, numpy) ...')\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'tensorflow', 'matplotlib', 'numpy'])\n",
    "    print('Instalação concluída. Reinicie o runtime se necessário.')\n",
    "else:\n",
    "    print('Não detectado Google Colab. Para instalar localmente, execute:')\n",
    "    print('\n",
    "python -m pip install tensorflow matplotlib numpy\n",
    "')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4277fa9e",
   "metadata": {},
   "source": [
    "## Checar ambiente e importar bibliotecas\n",
    "A célula abaixo importa as bibliotecas principais, exibe a versão do TensorFlow e lista GPUs disponíveis (se houver)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4dd415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('GPUs found:', gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f5a90",
   "metadata": {},
   "source": [
    "## Carregar e pré-processar MNIST\n",
    "Vamos carregar os dados MNIST, normalizar os pixels para [0,1] e preparar as dimensões para a CNN. Também mostramos algumas amostras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ca89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalizar e expandir canal\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = np.expand_dims(x_train, -1)  # (60000, 28, 28, 1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "print('x_train shape:', x_train.shape, 'y_train shape:', y_train.shape)\n",
    "\n",
    "# Mostrar as 9 primeiras imagens de treino\n",
    "plt.figure(figsize=(6,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_train[i].squeeze(), cmap='gray')\n",
    "    plt.title(str(y_train[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074fe3d5",
   "metadata": {},
   "source": [
    "## Definir a arquitetura da CNN\n",
    "Arquitetura simples para demonstração: Conv(32) -> Pool -> Conv(64) -> Pool -> Dense(128) -> Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_simple_cnn(input_shape=(28,28,1), num_classes=10):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_simple_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6922d89",
   "metadata": {},
   "source": [
    "## Compilar e treinar (com callbacks)\n",
    "Usamos Adam e sparse categorical crossentropy (rótulos como inteiros). Adicionamos EarlyStopping e ModelCheckpoint para salvar o melhor modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3710dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Salvar melhor modelo localmente (runtime)\n",
    "checkpoint_path = 'best_model.h5'\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=15,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b525ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot das curvas de treino/validação\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5397d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f2b600",
   "metadata": {},
   "source": [
    "## Prever e mostrar algumas imagens\n",
    "Mostramos previsões para as primeiras 25 imagens do conjunto de teste e colorimos o rótulo em verde quando correto e vermelho quando incorreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x_test[:25])\n",
    "pred_labels = np.argmax(preds, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_test[i].squeeze(), cmap=plt.cm.binary)\n",
    "    color = 'green' if pred_labels[i] == y_test[i] else 'red'\n",
    "    plt.xlabel(f'pred: {pred_labels[i]}  true: {y_test[i]}', color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4215b01",
   "metadata": {},
   "source": [
    "## Salvar o modelo (opcional no Drive)\n",
    "Se você estiver no Colab e quiser guardar o modelo no Google Drive, descomente e execute a célula abaixo; ela monta o Drive e salva o arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177bcf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula opcional: salvar em Google Drive (executar apenas em Colab)\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    dest = '/content/drive/MyDrive/simple_cnn_mnist.h5'\n",
    "    model.save(dest)\n",
    "    print('Modelo salvo em', dest)\n",
    "else:\n",
    "    # Salvar localmente no runtime (download manual depois)\n",
    "    local_path = 'simple_cnn_mnist.h5'\n",
    "    model.save(local_path)\n",
    "    print('Modelo salvo localmente em', local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c66186",
   "metadata": {},
   "source": [
    "---\n",
    "## Notas finais e como rodar localmente\n",
    "- Para rodar localmente, crie um ambiente virtual e instale dependências:\n",
    "  ```powershell\n",
    "  python -m venv .venv\n",
    "  .venvcriptsctivate.ps1\n",
    "  python -m pip install --upgrade pip\n",
    "  python -m pip install tensorflow matplotlib numpy\n",
    "  ```\n",
    "- Em sistemas sem GPU ou com GPU incompatível, instale a versão apropriada do TensorFlow conforme sua GPU/OS.\n",
    "- Próximos passos sugeridos: aumentar epochs, experimentar Fashion-MNIST/CIFAR-10, usar data augmentation, e hiperparâmetros.\n",
    "\n",
    "Pronto — notebook refeito e melhorado. Se quiser, eu adiciono comentários por célula, um `requirements.txt` no repositório ou fixo versões dos pacotes."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
