{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d148a2",
   "metadata": {},
   "source": [
    "# Treinamento de rede neural para queda livre (Google Colab)\n",
    "\n",
    "Notebook pronto para rodar no Google Colab. Gera uma base sintética com a equação da queda livre, treina uma rede neural (Keras) que prediz a posição y dada a altura inicial h0 e o tempo t, salva o dataset e o modelo no Google Drive (opcional) e faz comparação entre predição e fórmula analítica.\n",
    "\n",
    "Rodar as células na ordem. Comentários em Português."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a12854",
   "metadata": {},
   "source": [
    "## 1) Configuração e montagem do Google Drive (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec79178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar o Google Drive (opcional)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Defina uma pasta no Drive para salvar dataset e modelo, por exemplo:\n",
    "DRIVE_DIR = '/content/drive/MyDrive/ObjetoQueda'\n",
    "import os\n",
    "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "print('Pasta de salvamento:', DRIVE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb59d5c",
   "metadata": {},
   "source": [
    "## 2) Geração da base de dados (equação da queda livre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera dados sintéticos da queda livre e salva em CSV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parâmetros físicos\n",
    "g = 9.80665  # m/s^2\n",
    "\n",
    "def posicao_queda(h0, t, g=g):\n",
    "    \"\"\"Equação analítica: y(t) = h0 - 0.5*g*t^2\n",
    "    Retorna posição y (m).\n",
    "    \"\"\"\n",
    "    return h0 - 0.5 * g * t**2\n",
    "\n",
    "# Gerar dataset\n",
    "np.random.seed(42)\n",
    "N_heights = 500  # diferentes alturas iniciais\n",
    "N_times_per_height = 50\n",
    "h0_vals = np.random.uniform(0.5, 100.0, size=N_heights)  # alturas entre 0.5 e 100 m\n",
    "data = []\n",
    "for h0 in h0_vals:\n",
    "    # tempos até o objeto atingir o chão (resolver h0 - 0.5*g*t^2 = 0)\n",
    "    t_max = np.sqrt(2 * h0 / g)\n",
    "    # amostras de tempo uniformes entre 0 e t_max\n",
    "    ts = np.random.uniform(0, t_max, size=N_times_per_height)\n",
    "    ys = posicao_queda(h0, ts)\n",
    "    # adicionar ruído pequeno nas posições para simular medições\n",
    "    noise = np.random.normal(scale=0.01 * h0, size=ys.shape)  # ruído proporcional\n",
    "    ys_noisy = ys + noise\n",
    "    for t, y in zip(ts, ys_noisy):\n",
    "        data.append([h0, t, y])\n",
    "\n",
    "df = pd.DataFrame(data, columns=['h0', 't', 'y'])\n",
    "print('Dataset gerado com', len(df), 'amostras')\n",
    "# salvar localmente e no Drive\n",
    "LOCAL_DIR = '/content'\n",
    "local_csv = os.path.join(LOCAL_DIR, 'objeto_queda_dataset.csv')\n",
    "df.to_csv(local_csv, index=False)\n",
    "print('Salvo em', local_csv)\n",
    "drive_csv = os.path.join(DRIVE_DIR, 'objeto_queda_dataset.csv')\n",
    "df.to_csv(drive_csv, index=False)\n",
    "print('Também salvo em Drive:', drive_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039447f8",
   "metadata": {},
   "source": [
    "## 3) Treinamento da rede neural (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55159943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar uma rede neural simples para predizer y a partir de h0 e t\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# carregar dataset\n",
    "df = pd.read_csv(local_csv)\n",
    "# features e alvo\n",
    "X = df[['h0', 't']].values\n",
    "y = df['y'].values\n",
    "\n",
    "# dividir em treino/val/teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, random_state=42)\n",
    "\n",
    "# normalização simples\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler_X.transform(X_train)\n",
    "X_val_s = scaler_X.transform(X_val)\n",
    "X_test_s = scaler_X.transform(X_test)\n",
    "\n",
    "# modelo\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(2,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# callbacks para salvar melhor peso\n",
    "checkpoint_path = os.path.join(DRIVE_DIR, 'model_checkpoint.h5')\n",
    "cp = keras.callbacks.ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss')\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_s, y_train, epochs=200, batch_size=64, validation_data=(X_val_s, y_val), callbacks=[cp, es])\n",
    "\n",
    "# salvar o modelo final\n",
    "final_model_path = os.path.join(DRIVE_DIR, 'modelo_objeto_queda.h5')\n",
    "model.save(final_model_path)\n",
    "print('Modelo salvo em', final_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae2fa6",
   "metadata": {},
   "source": [
    "## 4) Avaliação e comparação com a fórmula analítica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo salvo e comparar previsões com fórmula analítica\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(final_model_path)\n",
    "\n",
    "# previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test_s).flatten()\n",
    "# comparação com fórmula analítica sem ruído\n",
    "h0_test = X_test[:,0]\n",
    "t_test = X_test[:,1]\n",
    "y_true_analytic = posicao_queda(h0_test, t_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "mse_model = mean_squared_error(y_test, y_pred)\n",
    "mae_model = mean_absolute_error(y_test, y_pred)\n",
    "mse_analytic = mean_squared_error(y_test, y_true_analytic)\n",
    "mae_analytic = mean_absolute_error(y_test, y_true_analytic)\n",
    "\n",
    "print('MSE (modelo) =', mse_model)\n",
    "print('MAE (modelo) =', mae_model)\n",
    "print('MSE (analítico) =', mse_analytic)\n",
    "print('MAE (analítico) =', mae_analytic)\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.scatter(y_test, y_pred, s=5, alpha=0.6, label='modelo pred vs medidos')\n",
    "plt.scatter(y_test, y_true_analytic, s=5, alpha=0.6, label='analítico vs medidos')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--')\n",
    "plt.legend()\n",
    "plt.xlabel('y medido (com ruído)')\n",
    "plt.ylabel('y previsto')\n",
    "plt.title('Comparação: modelo ML vs fórmula analítica')\n",
    "plt.show()\n",
    "\n",
    "# salvar resultados de comparação\n",
    "results_df = pd.DataFrame({'h0':h0_test, 't':t_test, 'y_measured': y_test, 'y_pred': y_pred, 'y_analytic': y_true_analytic})\n",
    "results_csv = os.path.join(DRIVE_DIR, 'comparacao_resultados.csv')\n",
    "results_df.to_csv(results_csv, index=False)\n",
    "print('Resultados salvos em', results_csv)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
