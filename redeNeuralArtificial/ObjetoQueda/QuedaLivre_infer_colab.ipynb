{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoVieiraGuimaraes/MiniCursoPalestra/blob/main/redeNeuralArtificial/ObjetoQueda/QuedaLivre_infer_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f26898d7",
      "metadata": {
        "id": "f26898d7"
      },
      "source": [
        "# Inferência — Queda Livre (Colab)\n",
        "\n",
        "Notebook para carregar o modelo treinado (`model/fall_model`) gerado pelo `QuedaLivre_colab.ipynb` e fazer previsões a partir de tempos (t)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a6e9b37",
      "metadata": {
        "id": "3a6e9b37"
      },
      "outputs": [],
      "source": [
        "# Célula 1 — montar Drive no Colab (opcional)\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print('Drive montado. Copie a pasta model/ para /content/drive/MyDrive/... se quiser persistir o modelo.')\n",
        "else:\n",
        "    print('Executando localmente — verifique se a pasta model/ existe.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca25ba6",
      "metadata": {
        "id": "3ca25ba6"
      },
      "source": [
        "### 1) Preparação da inferência\n",
        "\n",
        "Propivo: importar bibliotecas necessárias para inferência, configurar caminhos e carregar utilitários (por exemplo, montar o Google Drive se necessário).\n",
        "\n",
        "Entradas: arquivos do modelo em `model/` (modelo e scalers).\n",
        "\n",
        "Saídas: objetos de I/O disponíveis para a sessão e mensagens de status.\n",
        "\n",
        "Dicas: verifique o caminho dos arquivos `model/` antes de rodar; no Colab monte o Drive para persistência.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43940666",
      "metadata": {
        "id": "43940666"
      },
      "outputs": [],
      "source": [
        "# Célula 2 — carregar modelo e scalers\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "MODEL_PATH = 'model/fall_model'\n",
        "SCALER_PATH = 'model/scaler.npz'\n",
        "\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print('Modelo não encontrado em', MODEL_PATH, '\\nSe você estiver no Colab monte o Drive e copie a pasta model/ para este runtime, ou execute o notebook de treino.')\n",
        "else:\n",
        "    model = load_model(MODEL_PATH)\n",
        "    sc = np.load(SCALER_PATH)\n",
        "    t_mean, t_std = sc['t_mean'], sc['t_std']\n",
        "    s_mean, s_std = sc['s_mean'], sc['s_std']\n",
        "    print('Modelo e scalers carregados com sucesso.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb23df0d",
      "metadata": {
        "id": "bb23df0d"
      },
      "source": [
        "### 2) Carregar modelo e scalers\n",
        "\n",
        "Propósito: carregar o modelo treinado (`model/fall_model`) e os scalers salvos (`model/scaler.npz`) para normalizar entradas/saídas durante inferência.\n",
        "\n",
        "Entradas: arquivos em `model/`.\n",
        "\n",
        "Saídas: variáveis `mdl`, `t_mean`, `t_std`, `s_mean`, `s_std` prontas para realizar predições.\n",
        "\n",
        "Dicas:\n",
        "- Se os arquivos não existirem, execute o notebook de treino para criá-los ou copie do Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97d2ce28",
      "metadata": {
        "id": "97d2ce28"
      },
      "outputs": [],
      "source": [
        "# Célula 3 — função de predição interativa\n",
        "import numpy as np\n",
        "def predict_time(t_seconds):\n",
        "    t_arr = np.array([[float(t_seconds)]], dtype=np.float32)\n",
        "    t_n = (t_arr - t_mean) / t_std\n",
        "    s_n = model.predict(t_n)\n",
        "    s = s_n * s_std + s_mean\n",
        "    return float(s[0,0])\n",
        "\n",
        "# exemplo\n",
        "if 'model' in globals():\n",
        "    for t in [0.5, 1.0, 2.0]:\n",
        "        print(t, 's ->', predict_time(t))\n",
        "else:\n",
        "    print('Modelo não carregado — execute a célula de carregamento primeiro.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d187bc8",
      "metadata": {
        "id": "4d187bc8"
      },
      "source": [
        "### 3) Funções utilitárias de inferência\n",
        "\n",
        "Propósito: definir funções como `predict_from_time` que aceitam tempos (um ou vetor) e retornam previsões de posição `s` usando o modelo carregado e os scalers.\n",
        "\n",
        "Entradas: valores `t` (float ou iterável).\n",
        "\n",
        "Saídas: valores de `s` preditos (float ou array). Também podem salvar ou fazer download de resultados em lote.\n",
        "\n",
        "Dicas:\n",
        "- Tip: wrap inputs como arrays numpy e trate shapes consistentemente para evitar erros de dimensão.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfbf600",
      "metadata": {
        "id": "9dfbf600"
      },
      "outputs": [],
      "source": [
        "# Célula 4 — inferência em lote via upload CSV (coluna com tempos em segundos)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for name in uploaded:\n",
        "        import io\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(io.BytesIO(uploaded[name]))\n",
        "        if df.shape[1] == 1:\n",
        "            times = df.iloc[:,0].values\n",
        "        elif 't' in df.columns:\n",
        "            times = df['t'].values\n",
        "        else:\n",
        "            raise ValueError('CSV deve ter coluna única com tempos ou coluna chamada t')\n",
        "        preds = [predict_time(float(x)) for x in times]\n",
        "        out_df = pd.DataFrame({'t': times, 's_pred': preds})\n",
        "        out_name = 'predictions_' + name\n",
        "        out_df.to_csv(out_name, index=False)\n",
        "        files.download(out_name)\n",
        "except Exception as e:\n",
        "    print('Upload em lote não disponível ou falhou:', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79ce9548",
      "metadata": {
        "id": "79ce9548"
      },
      "source": [
        "### 4) Exemplo em lote / download de resultados\n",
        "\n",
        "Propósito: permitir upload de um CSV com vários tempos, executar inferência em lote e fornecer download dos resultados (ou salvar no Drive).\n",
        "\n",
        "Entradas: CSV com coluna `t` (tempos em segundos).\n",
        "\n",
        "Saídas: arquivo CSV com previsões `s` e mensagens de status.\n",
        "\n",
        "Dicas:\n",
        "- Valide os valores de `t` no CSV (nulos, negativos) antes de predizer.\n",
        "- Para arquivos grandes, processe em batches para economizar memória.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffeeb89f",
      "metadata": {
        "id": "ffeeb89f"
      },
      "source": [
        "---\n",
        "### Dicas\n",
        "- Se quiser salvar o resultado no Drive, copie o arquivo `predictions_*.csv` para uma pasta dentro de `/content/drive/MyDrive/`.\n",
        "- Para adaptar o notebook para estimar tempo a partir de distância, carregue um modelo treinado nessa tarefa ou gere um dataset invertido no notebook de treino."
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}