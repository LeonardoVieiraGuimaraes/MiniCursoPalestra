{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d17c1da7",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LeonardoVieiraGuimaraes/MiniCursoPalestra/blob/main/redeNeuralArtificial/ObjetoQueda/QuedaLivre_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d6c6d4",
      "metadata": {
        "id": "29d6c6d4"
      },
      "source": [
        "# Queda Livre — demonstração e rede neural (Colab)\n",
        "\n",
        "Este notebook demonstra a fórmula de queda livre e treina uma pequena rede neural para aprender a relação entre tempo (t) e distância (s). Foi preparado para rodar no Google Colab ou em Jupyter local."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb6a034",
      "metadata": {
        "id": "9bb6a034"
      },
      "source": [
        "## Fórmula física\n",
        "\n",
        "Para queda livre sem resistência do ar e com aceleração da gravidade `g`, a posição `s(t)` é:\n",
        "\n",
        "s(t) = s0 + v0 * t + 0.5 * g * t^2\n",
        "\n",
        "Neste notebook usamos `s0 = 0` e `v0 = 0`, portanto `s(t) = 0.5 * g * t^2` com `g = 9.81 m/s^2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb3c2c0",
      "metadata": {
        "id": "aeb3c2c0"
      },
      "outputs": [],
      "source": [
        "# Célula 1 — preparar ambiente no Colab de forma segura\n",
        "# Evitamos instalar TensorFlow/numpy para não sobrescrever versões pré-instaladas no Colab\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    print('Executando no Colab. Usaremos as bibliotecas pré-instaladas para evitar conflitos.')\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        print('TensorFlow disponível — versão:', tf.__version__)\n",
        "    except Exception:\n",
        "        print('TensorFlow não encontrado no runtime. Se necessário, instale uma versão compatível manualmente.')\n",
        "    # atualizar apenas pacotes não-críticos (matplotlib)\n",
        "    try:\n",
        "        get_ipython().system('pip -q install -U matplotlib')\n",
        "    except Exception:\n",
        "        pass\n",
        "else:\n",
        "    print('Não detectado Colab — para execução local certifique-se de ter um ambiente virtual e instale dependências:')\n",
        "    print('  python -m venv .venv')\n",
        "    print(r'  .venv\\Scripts\\Activate.ps1  (PowerShell)')\n",
        "    print('  pip install numpy matplotlib tensorflow')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c70f29e3",
      "metadata": {
        "id": "c70f29e3"
      },
      "source": [
        "### 1) Preparação do ambiente\n",
        "\n",
        "Propósito: detectar se estamos executando no Google Colab e preparar o ambiente de forma segura, sem reinstalar pacotes críticos (TensorFlow/numpy) que podem causar conflitos no runtime.\n",
        "\n",
        "Entradas: nenhuma.\n",
        "\n",
        "Saídas: variáveis no namespace (`IN_COLAB`) e mensagens informativas sobre o ambiente; atualização de pacotes não-críticos (opcional).\n",
        "\n",
        "Notas de debug:\n",
        "- Se o Colab não tiver TensorFlow, a célula informa como instalar manualmente.\n",
        "- Em execução local, instrui sobre criação de virtualenv e instalação de dependências.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12af37f9",
      "metadata": {
        "id": "12af37f9"
      },
      "outputs": [],
      "source": [
        "# Célula 2 — gerar dataset (t -> s)\n",
        "import numpy as np\n",
        "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
        "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
        "\n",
        "def generate_dataset(n_samples=5000, t_min=0.0, t_max=10.0, noise_std=0.0, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    t = rng.uniform(t_min, t_max, size=(n_samples, 1)).astype(np.float32)\n",
        "    s = free_fall_distance(t).astype(np.float32)\n",
        "    if noise_std > 0:\n",
        "        s += rng.normal(0, noise_std, size=s.shape).astype(np.float32)\n",
        "    return t, s\n",
        "\n",
        "t_train, s_train = generate_dataset(5000, 0.0, 10.0, noise_std=0.0, seed=1)\n",
        "t_test, s_test = generate_dataset(1000, 0.0, 10.0, noise_std=0.0, seed=2)\n",
        "\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "np.savez_compressed('data/dataset.npz', t_train=t_train, s_train=s_train, t_test=t_test, s_test=s_test)\n",
        "print('Dataset salvo em data/dataset.npz — exemplos:')\n",
        "print('t[0]=', t_train[0,0], 's[0]=', s_train[0,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7087d6",
      "metadata": {
        "id": "7a7087d6"
      },
      "source": [
        "Gerar arquivo de inferência (CSV/NPZ):\n",
        "Esta célula cria um arquivo `data/times_for_infer.csv` contendo uma coluna `t` com 100 valores uniformes entre 0 e 10s. Também salva `data/dataset_infer.npz` com `t` e `s_true` para referência/validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9439c1b8",
      "metadata": {
        "id": "9439c1b8"
      },
      "outputs": [],
      "source": [
        "# Célula adicional — cria arquivos para inferência em lote\n",
        "import numpy as np\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "# 100 tempos uniformes entre 0 e 10s\n",
        "t_infer = np.linspace(0.0, 10.0, num=100, dtype=np.float32).reshape(-1,1)\n",
        "# calcula a posição verdadeira sem ruído para referência\n",
        "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
        "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
        "s_true = free_fall_distance(t_infer)\n",
        "# salvar CSV com coluna 't' (compatível com QuedaLivre_infer_colab upload CSV)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'t': t_infer.flatten()})\n",
        "csv_path = 'data/times_for_infer.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "# salvar npz com t e s_true\n",
        "np.savez_compressed('data/dataset_infer.npz', t=t_infer, s_true=s_true)\n",
        "print('Arquivos gerados:')\n",
        "print(' -', csv_path)\n",
        "print(\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b91add0",
      "metadata": {
        "id": "2b91add0"
      },
      "source": [
        "### 2) Geração do dataset\n",
        "\n",
        "Propósito: gerar um dataset sintético mapeando tempo `t` para posição `s(t)` usando a fórmula da queda livre. Suporta adicionar ruído nas medições para simular imperfeições.\n",
        "\n",
        "Entradas: parâmetros de geração — número de amostras, intervalo de tempo (t_min, t_max), desvio padrão do ruído, semente RNG.\n",
        "\n",
        "Saídas: arrays `t_train`, `s_train`, `t_test`, `s_test`, e arquivo salvo `data/dataset.npz`.\n",
        "\n",
        "Dicas:\n",
        "- Use `seed` para reprodutibilidade.\n",
        "- Se quiser incluir arrasto, substitua a função analítica por um integrador numérico (ex.: RK4) e re-gere o dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f148f7bb",
      "metadata": {
        "id": "f148f7bb"
      },
      "outputs": [],
      "source": [
        "# Célula 3 — treinar um modelo Keras para mapear t -> s\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.load('data/dataset.npz')\n",
        "t_train = data['t_train']\n",
        "s_train = data['s_train']\n",
        "t_test = data['t_test']\n",
        "s_test = data['s_test']\n",
        "\n",
        "# normalização simples\n",
        "t_mean, t_std = t_train.mean(), t_train.std()\n",
        "s_mean, s_std = s_train.mean(), s_train.std()\n",
        "t_train_n = (t_train - t_mean) / t_std\n",
        "t_test_n = (t_test - t_mean) / t_std\n",
        "s_train_n = (s_train - s_mean) / s_std\n",
        "s_test_n = (s_test - s_mean) / s_std\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(1,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "history = model.fit(t_train_n, s_train_n, epochs=60, batch_size=64, validation_split=0.1, verbose=2)\n",
        "\n",
        "# avaliar\n",
        "test_loss, test_mae = model.evaluate(t_test_n, s_test_n, verbose=0)\n",
        "print(f'Teste - MSE: {test_loss:.6f}, MAE: {test_mae:.6f}')\n",
        "\n",
        "os.makedirs('model', exist_ok=True)\n",
        "# Salvar usando a extensão recomendada .keras para compatibilidade com Keras\n",
        "model.save('model/fall_model.keras')\n",
        "np.savez('model/scaler.npz', t_mean=t_mean, t_std=t_std, s_mean=s_mean, s_std=s_std)\n",
        "print('Modelo e scalers salvos em model/')\n",
        "\n",
        "# plot do histórico\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2367c1bf",
      "metadata": {
        "id": "2367c1bf"
      },
      "source": [
        "### 3) Treinamento do modelo\n",
        "\n",
        "Propósito: carregar o dataset salvo, normalizar as variáveis, definir e treinar um modelo Keras (MLP) que mapeia `t -> s`.\n",
        "\n",
        "Entradas: arquivo `data/dataset.npz` gerado anteriormente.\n",
        "\n",
        "Saídas: modelo treinado salvo em `model/fall_model`, scalers salvos em `model/scaler.npz`, e gráficos do histórico de treino.\n",
        "\n",
        "Dicas:\n",
        "- Normalize `t` e `s` para melhorar convergência do treinamento.\n",
        "- Ajuste `epochs`, `batch_size` e arquitetura para balancear erro e tempo de execução.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d1961d",
      "metadata": {
        "id": "70d1961d"
      },
      "outputs": [],
      "source": [
        "# Célula 4 — uso do modelo treinado: prever s a partir de t\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "mdl = load_model('model/fall_model')\n",
        "sc = np.load('model/scaler.npz')\n",
        "t_mean, t_std = sc['t_mean'], sc['t_std']\n",
        "s_mean, s_std = sc['s_mean'], sc['s_std']\n",
        "\n",
        "def predict_from_time(t_seconds):\n",
        "    t_arr = np.array([[float(t_seconds)]], dtype=np.float32)\n",
        "    t_n = (t_arr - t_mean) / t_std\n",
        "    s_n = mdl.predict(t_n)\n",
        "    s = s_n * s_std + s_mean\n",
        "    return float(s[0,0])\n",
        "\n",
        "# exemplo interativo\n",
        "for t in [0.5, 1.0, 2.0, 3.0]:\n",
        "    print(t, 's -> s=', predict_from_time(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6812083",
      "metadata": {
        "id": "a6812083"
      },
      "source": [
        "### 4) Inferência e uso do modelo\n",
        "\n",
        "Propósito: demonstrar como carregar o modelo e scalers salvos e usar o modelo para prever `s` a partir de `t` (predição pontual e em lote).\n",
        "\n",
        "Entradas: `model/fall_model` e `model/scaler.npz`.\n",
        "\n",
        "Saídas: funções utilitárias (`predict_from_time`) e exemplos de uso imprimindo previsões.\n",
        "\n",
        "Dicas:\n",
        "- Se for usar no Colab e quiser persistir o modelo, monte o Google Drive e copie `model/` para `drive/MyDrive/...`.\n",
        "- Para inverter (estimativa de `t` a partir de `s`), gere um dataset com `s` como entrada e treine um novo modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c174aff",
      "metadata": {
        "id": "5c174aff"
      },
      "source": [
        "---\n",
        "### Notas finais\n",
        "- Para salvar o modelo no seu Google Drive monte o Drive e copie a pasta `model/` para `/content/drive/MyDrive/...`\n",
        "- Se quiser estimar t a partir de s, gere dataset invertido (s como entrada) e treine similarmente."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
