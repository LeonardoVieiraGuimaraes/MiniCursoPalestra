{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aba105db",
      "metadata": {},
      "source": [
        "# Queda Livre — Colab-ready\n",
        "\n",
        "Este notebook gera um dataset sintético de queda livre (tempo → posição), treina uma rede neural simples para estimar a posição a partir do tempo, e salva os artefatos necessários para inferência.\n",
        "\n",
        "Siga a ordem: `Setup` → `Gerar dados` → `Treinar` → `Exportar SavedModel (opcional)`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "240b536f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup para Colab / Jupyter\n",
        "# - Detecta se estamos no Google Colab\n",
        "# - (Opcional) monta o Drive se desejar persistir arquivos\n",
        "# - Garante pastas `data/` e `model/`\n",
        "# - Não força instalação do TensorFlow (Colab já possui TF); instala apenas pacotes leves se estiverem ausentes\n",
        "import os\n",
        "import sys\n",
        "import importlib\n",
        "import subprocess\n",
        "\n",
        "IN_COLAB = False\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "print('Google Colab:', IN_COLAB)\n",
        "\n",
        "# Se quiser persistir artefatos automaticamente no Drive, mude para True\n",
        "MOUNT_DRIVE = False\n",
        "if IN_COLAB and MOUNT_DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print('Drive montado em /content/drive')\n",
        "\n",
        "# Instala pacotes leves se faltarem (não instala tensorflow)\n",
        "def pip_install(pkg):\n",
        "    print(f'Instalando {pkg}...')\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
        "\n",
        "for pkg in ('pandas', 'scikit-learn'):\n",
        "    if importlib.util.find_spec(pkg) is None:\n",
        "        pip_install(pkg)\n",
        "    else:\n",
        "        print(f'{pkg} já presente')\n",
        "\n",
        "# Garantir diretórios\n",
        "os.makedirs('data', exist_ok=True)\n",
        "os.makedirs('model', exist_ok=True)\n",
        "\n",
        "# Seeds previsíveis para demonstração\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    tf.random.set_seed(42)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "\n",
        "print('\\nSetup concluído. Execute as células abaixo (geração de dados → treino → export) na ordem.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29d6c6d4",
      "metadata": {
        "id": "29d6c6d4"
      },
      "source": [
        "### 1) Preparação do ambiente\n",
        "\n",
        "Propósito: detectar se estamos executando no Google Colab e preparar o ambiente de forma segura, sem reinstalar pacotes críticos (TensorFlow/numpy) que podem causar conflitos no runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb6a034",
      "metadata": {
        "id": "9bb6a034"
      },
      "source": [
        "### 2) Preparação rápida do dataset e parâmetros\n",
        "\n",
        "Nesta seção geramos os dados sintéticos que serão usados no treino e nos testes. Você pode ajustar `noise_std` para simular medições ruidosas ou substituir a função analítica por um integrador numérico para incluir arrasto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeb3c2c0",
      "metadata": {
        "id": "aeb3c2c0"
      },
      "outputs": [],
      "source": [
        "# 2) Gerar dataset (t -> s)\n",
        "import numpy as np\n",
        "\n",
        "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
        "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
        "\n",
        "\n",
        "def generate_dataset(n_samples=5000, t_min=0.0, t_max=10.0, noise_std=0.0, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    t = rng.uniform(t_min, t_max, size=(n_samples, 1)).astype(np.float32)\n",
        "    s = free_fall_distance(t).astype(np.float32)\n",
        "    if noise_std > 0:\n",
        "        s += rng.normal(0, noise_std, size=s.shape).astype(np.float32)\n",
        "    return t, s\n",
        "\n",
        "\n",
        "t_train, s_train = generate_dataset(5000, 0.0, 10.0, noise_std=0.0, seed=1)\n",
        " t_test, s_test = generate_dataset(1000, 0.0, 10.0, noise_std=0.0, seed=2)\n",
        "\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "np.savez_compressed('data/dataset.npz', t_train=t_train, s_train=s_train, t_test=t_test, s_test=s_test)\n",
        "print('Dataset salvo em data/dataset.npz — exemplos:')\n",
        "print('t[0]=', t_train[0,0], 's[0]=', s_train[0,0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c70f29e3",
      "metadata": {
        "id": "c70f29e3"
      },
      "source": [
        "Gerar arquivo de inferência (CSV/NPZ):\n",
        "\n",
        "Esta célula cria um arquivo `data/times_for_infer.csv` contendo uma coluna `t` com 100 valores uniformes entre 0 e 10s. Também salva `data/dataset_infer.npz` com `t` e `s_true` para referência/validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12af37f9",
      "metadata": {
        "id": "12af37f9"
      },
      "outputs": [],
      "source": [
        "# Cria arquivos para inferência em lote\n",
        "import numpy as np\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "# 100 tempos uniformes entre 0 e 10s\n",
        "t_infer = np.linspace(0.0, 10.0, num=100, dtype=np.float32).reshape(-1,1)\n",
        "# calcula a posição verdadeira sem ruído para referência\n",
        "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
        "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
        "s_true = free_fall_distance(t_infer)\n",
        "# salvar CSV com coluna 't' (compatível com QuedaLivre_infer_colab upload CSV)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'t': t_infer.flatten()})\n",
        "csv_path = 'data/times_for_infer.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "# salvar npz com t e s_true\n",
        "np.savez_compressed('data/dataset_infer.npz', t=t_infer, s_true=s_true)\n",
        "print('Arquivos gerados:')\n",
        "print(' -', csv_path)\n",
        "print(' - data/dataset_infer.npz')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7087d6",
      "metadata": {
        "id": "7a7087d6"
      },
      "source": [
        "### 3) Treinamento do modelo\n",
        "\n",
        "A célula abaixo carrega `data/dataset.npz`, normaliza os dados, monta uma rede rasa e treina. Ao final salva `model/fall_model.keras` e `model/scaler.npz`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9439c1b8",
      "metadata": {
        "id": "9439c1b8"
      },
      "outputs": [],
      "source": [
        "# Célula adicional — cria arquivos para inferência em lote\n",
        "import numpy as np\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "# 100 tempos uniformes entre 0 e 10s\n",
        "t_infer = np.linspace(0.0, 10.0, num=100, dtype=np.float32).reshape(-1,1)\n",
        "# calcula a posição verdadeira sem ruído para referência\n",
        "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
        "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
        "s_true = free_fall_distance(t_infer)\n",
        "# salvar CSV com coluna 't' (compatível com QuedaLivre_infer_colab upload CSV)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame({'t': t_infer.flatten()})\n",
        "csv_path = 'data/times_for_infer.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "# salvar npz com t e s_true\n",
        "np.savez_compressed('data/dataset_infer.npz', t=t_infer, s_true=s_true)\n",
        "print('Arquivos gerados:')\n",
        "print(' -', csv_path)\n",
        "print(' - data/dataset_infer.npz')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b91add0",
      "metadata": {
        "id": "2b91add0"
      },
      "source": [
        "### 2) Geração do dataset\n",
        "\n",
        "Propósito: gerar um dataset sintético mapeando tempo `t` para posição `s(t)` usando a fórmula da queda livre. Suporta adicionar ruído nas medições para simular imperfeições.\n",
        "\n",
        "Entradas: parâmetros de geração — número de amostras, intervalo de tempo (t_min, t_max), desvio padrão do ruído, semente RNG.\n",
        "\n",
        "Saídas: arrays `t_train`, `s_train`, `t_test`, `s_test`, e arquivo salvo `data/dataset.npz`.\n",
        "\n",
        "Dicas:\n",
        "- Use `seed` para reprodutibilidade.\n",
        "- Se quiser incluir arrasto, substitua a função analítica por um integrador numérico (ex.: RK4) e re-gere o dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f148f7bb",
      "metadata": {
        "id": "f148f7bb"
      },
      "outputs": [],
      "source": [
        "# Treinamento do modelo\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = np.load('data/dataset.npz')\n",
        "t_train = data['t_train']\n",
        "s_train = data['s_train']\n",
        "t_test = data['t_test']\n",
        "s_test = data['s_test']\n",
        "\n",
        "# normalização simples\n",
        "t_mean, t_std = float(t_train.mean()), float(t_train.std())\n",
        "s_mean, s_std = float(s_train.mean()), float(s_train.std())\n",
        "t_train_n = (t_train - t_mean) / t_std\n",
        "t_test_n = (t_test - t_mean) / t_std\n",
        "s_train_n = (s_train - s_mean) / s_std\n",
        "s_test_n = (s_test - s_mean) / s_std\n",
        "\n",
        "def build_model():\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(1,)),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(1, activation='linear')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "history = model.fit(t_train_n, s_train_n, epochs=60, batch_size=64, validation_split=0.1, verbose=2)\n",
        "\n",
        "# avaliar\n",
        "test_loss, test_mae = model.evaluate(t_test_n, s_test_n, verbose=0)\n",
        "print(f'Teste - MSE: {test_loss:.6f}, MAE: {test_mae:.6f}')\n",
        "\n",
        "os.makedirs('model', exist_ok=True)\n",
        "model.save('model/fall_model.keras')\n",
        "# salve scalers como floats para evitar problemas no carregamento\n",
        "np.savez_compressed('model/scaler.npz', t_mean=t_mean, t_std=t_std, s_mean=s_mean, s_std=s_std)\n",
        "print('Modelo e scalers salvos em model/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2367c1bf",
      "metadata": {
        "id": "2367c1bf"
      },
      "source": [
        "### 4) Inferência e uso do modelo\n",
        "\n",
        "Esta seção mostra como carregar o modelo salvo e realizar predições (ex.: carregar `data/times_for_infer.csv`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70d1961d",
      "metadata": {
        "id": "70d1961d"
      },
      "outputs": [],
      "source": [
        "# Exemplo de inferência (carregando .keras e scalers)\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# procura por caminhos possíveis\n",
        "candidates = ['model/fall_model.keras', 'model/fall_model.h5', 'model/fall_model']\n",
        "model_path = None\n",
        "import os\n",
        "for c in candidates:\n",
        "    if os.path.exists(c):\n",
        "        model_path = c\n",
        "        break\n",
        "\n",
        "if model_path is None:\n",
        "    print('Nenhum modelo encontrado em model/. Rode a célula de treino primeiro.')\n",
        "else:\n",
        "    print('Carregando modelo de', model_path)\n",
        "    model = load_model(model_path)\n",
        "    scal = np.load('model/scaler.npz')\n",
        "    # carregar como floats\n",
        "    t_mean = float(scal['t_mean'])\n",
        "    t_std = float(scal['t_std'])\n",
        "    s_mean = float(scal['s_mean'])\n",
        "    s_std = float(scal['s_std'])\n",
        "\n",
        "    # função de predição rápida\n",
        "    def predict_time(t_values):\n",
        "        import numpy as np\n",
        "        t_arr = np.array(t_values, dtype=np.float32).reshape(-1,1)\n",
        "        t_n = (t_arr - t_mean) / t_std\n",
        "        s_n = model.predict(t_n, verbose=0)\n",
        "        s = s_n * s_std + s_mean\n",
        "        return s.flatten()\n",
        "\n",
        "    # exemplo: carregar CSV gerado anteriormente\n",
        "    import pandas as pd\n",
        "    if os.path.exists('data/times_for_infer.csv'):\n",
        "        df = pd.read_csv('data/times_for_infer.csv')\n",
        "        if 't' in df.columns:\n",
        "            preds = predict_time(df['t'].values)\n",
        "            print('Predições em lote (primeiros 5):', preds[:5])\n",
        "        else:\n",
        "            print('CSV encontrado, mas sem coluna t')\n",
        "    else:\n",
        "        print('Nenhum CSV de inferência encontrado (data/times_for_infer.csv)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6812083",
      "metadata": {
        "id": "a6812083"
      },
      "source": [
        "### 5) Como persistir os artefatos no Google Drive\n",
        "\n",
        "Se você executou este notebook no Colab e deseja salvar os artefatos (`model/` e `data/`) no seu Google Drive:\n",
        "\n",
        "1. Monte o Drive (se ainda não montou):\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "2. Copie os diretórios:\n",
        "\n",
        "```python\n",
        "import shutil\n",
        "shutil.copy('model/fall_model.keras', '/content/drive/MyDrive/fall_model.keras')\n",
        "shutil.copy('model/scaler.npz', '/content/drive/MyDrive/scaler.npz')\n",
        "shutil.copy('data/dataset.npz', '/content/drive/MyDrive/dataset.npz')\n",
        "shutil.copy('data/times_for_infer.csv', '/content/drive/MyDrive/times_for_infer.csv')\n",
        "```\n",
        "\n",
        "Ou copie a pasta inteira:\n",
        "\n",
        "```python\n",
        "!cp -r model /content/drive/MyDrive/\n",
        "!cp -r data /content/drive/MyDrive/\n",
        "```\n",
        "\n",
        "Observação: se preferir, ajuste os caminhos de destino no seu Drive para organizar os arquivos em uma pasta de curso/aula.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37c0e135",
      "metadata": {},
      "source": [
        "Observação: a exportação para SavedModel é opcional. Use-a apenas se precisar do diretório `model/fall_model/` para TFSMLayer ou deploy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c174aff",
      "metadata": {
        "id": "5c174aff"
      },
      "source": [
        "---\n",
        "\n",
        "Pronto. Execute as células de cima para baixo; se ocorrer qualquer erro, cole o traceback aqui e eu corrijo rapidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0514a1a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar SavedModel (opcional)\n",
        "# Uma pasta SavedModel (`model/fall_model`) é necessária se você quiser usar TFSMLayer ou ferramentas que esperam o formato SavedModel.\n",
        "# A célula abaixo tenta exportar automaticamente a partir do objeto Keras salvo: usa `model.export` (Keras 3) com fallback para `tf.saved_model.save`.\n",
        "import os\n",
        "import tensorflow as tf\n",
        "export_dir = 'model/fall_model'\n",
        "if os.path.exists(export_dir) and os.listdir(export_dir):\n",
        "    print('SavedModel já existe em', export_dir)\n",
        "else:\n",
        "    try:\n",
        "        # Keras 3: model.export cria SavedModel compatível\n",
        "        print('Tentando exportar SavedModel com model.export(...)')\n",
        "        model.export(export_dir)\n",
        "        print('Exportado com model.export para', export_dir)\n",
        "    except Exception as e:\n",
        "        print('model.export não disponível ou falhou:', e)\n",
        "        print('Tentando tf.saved_model.save como fallback...')\n",
        "        try:\n",
        "            tf.saved_model.save(model, export_dir)\n",
        "            print('SavedModel salvo em', export_dir)\n",
        "        except Exception as e2:\n",
        "            print('Falha ao salvar SavedModel:', e2)\n",
        "            print('Você ainda pode carregar o arquivo .keras com load_model(\"model/fall_model.keras\").')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
