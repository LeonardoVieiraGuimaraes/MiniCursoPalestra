{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d6c6d4",
   "metadata": {},
   "source": [
    "# Queda Livre — demonstração e rede neural (Colab)\n",
    "\n",
    "Este notebook demonstra a fórmula de queda livre e treina uma pequena rede neural para aprender a relação entre tempo (t) e distância (s). Foi preparado para rodar no Google Colab ou em Jupyter local."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6a034",
   "metadata": {},
   "source": [
    "## Fórmula física\n",
    "\n",
    "Para queda livre sem resistência do ar e com aceleração da gravidade `g`, a posição `s(t)` é:\n",
    "\n",
    "s(t) = s0 + v0 * t + 0.5 * g * t^2\n",
    "\n",
    "Neste notebook usamos `s0 = 0` e `v0 = 0`, portanto `s(t) = 0.5 * g * t^2` com `g = 9.81 m/s^2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1 — preparar ambiente no Colab de forma segura\n",
    "# Evitamos instalar TensorFlow/numpy para não sobrescrever versões pré-instaladas no Colab\n",
    "IN_COLAB = False\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print('Executando no Colab. Usaremos as bibliotecas pré-instaladas para evitar conflitos.')\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        print('TensorFlow disponível — versão:', tf.__version__)\n",
    "    except Exception:\n",
    "        print('TensorFlow não encontrado no runtime. Se necessário, instale uma versão compatível manualmente.')\n",
    "    # atualizar apenas pacotes não-críticos (matplotlib)\n",
    "    try:\n",
    "        get_ipython().system('pip -q install -U matplotlib')\n",
    "    except Exception:\n",
    "        pass\n",
    "else:\n",
    "    print('Não detectado Colab — para execução local certifique-se de ter um ambiente virtual e instale dependências:')\n",
    "    print('  python -m venv .venv')\n",
    "    print('  .venv\\Scripts\\Activate.ps1  (PowerShell)')\n",
    "    print('  pip install numpy matplotlib tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12af37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2 — gerar dataset (t -> s)\n",
    "import numpy as np\n",
    "def free_fall_distance(t, g=9.81, v0=0.0, s0=0.0):\n",
    "    return s0 + v0 * t + 0.5 * g * (t ** 2)\n",
    "\n",
    "def generate_dataset(n_samples=5000, t_min=0.0, t_max=10.0, noise_std=0.0, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    t = rng.uniform(t_min, t_max, size=(n_samples, 1)).astype(np.float32)\n",
    "    s = free_fall_distance(t).astype(np.float32)\n",
    "    if noise_std > 0:\n",
    "        s += rng.normal(0, noise_std, size=s.shape).astype(np.float32)\n",
    "    return t, s\n",
    "\n",
    "t_train, s_train = generate_dataset(5000, 0.0, 10.0, noise_std=0.0, seed=1)\n",
    "t_test, s_test = generate_dataset(1000, 0.0, 10.0, noise_std=0.0, seed=2)\n",
    "\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "np.savez_compressed('data/dataset.npz', t_train=t_train, s_train=s_train, t_test=t_test, s_test=s_test)\n",
    "print('Dataset salvo em data/dataset.npz — exemplos:')\n",
    "print('t[0]=', t_train[0,0], 's[0]=', s_train[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148f7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3 — treinar um modelo Keras para mapear t -> s\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.load('data/dataset.npz')\n",
    "t_train = data['t_train']\n",
    "s_train = data['s_train']\n",
    "t_test = data['t_test']\n",
    "s_test = data['s_test']\n",
    "\n",
    "# normalização simples\n",
    "t_mean, t_std = t_train.mean(), t_train.std()\n",
    "s_mean, s_std = s_train.mean(), s_train.std()\n",
    "t_train_n = (t_train - t_mean) / t_std\n",
    "t_test_n = (t_test - t_mean) / t_std\n",
    "s_train_n = (s_train - s_mean) / s_std\n",
    "s_test_n = (s_test - s_mean) / s_std\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(1,)),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "history = model.fit(t_train_n, s_train_n, epochs=60, batch_size=64, validation_split=0.1, verbose=2)\n",
    "\n",
    "# avaliar\n",
    "test_loss, test_mae = model.evaluate(t_test_n, s_test_n, verbose=0)\n",
    "print(f'Teste - MSE: {test_loss:.6f}, MAE: {test_mae:.6f}')\n",
    "\n",
    "os.makedirs('model', exist_ok=True)\n",
    "model.save('model/fall_model')\n",
    "np.savez('model/scaler.npz', t_mean=t_mean, t_std=t_std, s_mean=s_mean, s_std=s_std)\n",
    "print('Modelo e scalers salvos em model/')\n",
    "\n",
    "# plot do histórico\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4 — uso do modelo treinado: prever s a partir de t\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "mdl = load_model('model/fall_model')\n",
    "sc = np.load('model/scaler.npz')\n",
    "t_mean, t_std = sc['t_mean'], sc['t_std']\n",
    "s_mean, s_std = sc['s_mean'], sc['s_std']\n",
    "\n",
    "def predict_from_time(t_seconds):\n",
    "    t_arr = np.array([[float(t_seconds)]], dtype=np.float32)\n",
    "    t_n = (t_arr - t_mean) / t_std\n",
    "    s_n = mdl.predict(t_n)\n",
    "    s = s_n * s_std + s_mean\n",
    "    return float(s[0,0])\n",
    "\n",
    "# exemplo interativo\n",
    "for t in [0.5, 1.0, 2.0, 3.0]:\n",
    "    print(t, 's -> s=', predict_from_time(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c174aff",
   "metadata": {},
   "source": [
    "---\n",
    "### Notas finais\n",
    "- Para salvar o modelo no seu Google Drive monte o Drive e copie a pasta `model/` para `/content/drive/MyDrive/...`\n",
    "- Se quiser estimar t a partir de s, gere dataset invertido (s como entrada) e treine similarmente."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
